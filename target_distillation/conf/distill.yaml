defaults:
  - _self_
  - db: audioset_logits_sd
  - system: nt
  - model: logit_dist
hydra:
  run:
    dir: ${system.storage_root}/${experiment_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
loader:
  batch_size: 256
  num_workers: 8
# feature_extractor:
#   _target_: EfficientAT.models.preprocess.AugmentMelSTFT
#   sr: ${db.sample_rate}
#   win_length: 800
#   hopsize: 320
#   n_mels: 128
#   freqm: 48
#   timem: 0
feature_extractor:
  _target_: target_distillation.feature_extractor.LogMel
  sr: ${db.sample_rate}
  win_length: 3072
  n_fft: 4096
  hopsize: 500
  n_mels: 256
  freqm: 48
  timem: 0

optimizer:
  _target_: torch.optim.AdamW
  lr: 5e-3
  # lr: 8e-4
  weight_decay: 0.0001
trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: "gpu"
  num_nodes: 1
  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: ${hydra:run.dir}
    name: ${experiment_name}
  strategy: ddp
  # limit_train_batches: ${num_iterations}
  precision: 32
  max_epochs: ${epochs}
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
lr_schedule:
  warm_up_len: 0.02
  ramp_down_start: 0.02
  ramp_down_len: 0.98
  last_lr_value: 0.01
  # warm_up_len: 0.04
  # ramp_down_start: 0.4
  # ramp_down_len: 0.475
  # last_lr_value: 0.01
epochs: 150
# num_iterations: 167000
experiment_name: target_distillation
# +ckpt_path: path/to/checkpoint